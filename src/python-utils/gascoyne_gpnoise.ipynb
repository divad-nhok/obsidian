{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigation of geophysical sensor data to inform priors\n",
    "\n",
    "Since we don't have a really great idea of what constitutes a good set of priors for real data, here I try my best to sort out what is going on using what I hope will be simple, but robust, assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import GPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise and length scale characteristics for gravity and magnetism\n",
    "\n",
    "We've been running with some set of priors for gravity and magnetism, but in all fairness we have no idea what those should be.  We know they're both linear sensors that integrate over rock properties, with a 3-D sensitivity profile that gets broader with depth.  So by fitting a GP to them, we get some idea of the noise, and a lower limit on the relevant length scale.  Since they're on a grid, we could also consider the autocorrelation.\n",
    "\n",
    "This isn't really meant to be a Bayesian analysis, but it's meant to give us some idea of the order of magnitude of the noise in a model that's flexible enough to respond to changes, but that insists on smoothness so we can pick off the delta-function component of the covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gravdata = pd.read_csv(\"/Users/davidkohn/dev/obsidian/data/dataset1/gravity_400m_Gascoyne.txt\", header=0)\n",
    "print(gravdata.Latitude.min(), gravdata.Latitude.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gravdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gravdata = gravdata[np.abs(gravdata.Latitude + 24.85) < 0.05]\n",
    "gravdata = gravdata[np.abs(gravdata.Longitude - 116.1) < 0.05]\n",
    "print(gravdata.grid_code.min(), gravdata.grid_code.max())\n",
    "print(gravdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([gravdata.Latitude, gravdata.Longitude]).T\n",
    "Y = np.array([gravdata.grid_code]).T\n",
    "kernel = GPy.kern.Matern32(2)\n",
    "print \"X.shape =\", X.shape\n",
    "print \"Y.shape =\", Y.shape\n",
    "model = GPy.models.GPRegression(X, Y, kernel)\n",
    "model.optimize(messages=True)\n",
    "fig = model.plot()\n",
    "print model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems pretty weird -- the gravity data seems to have a very long length scale and no obvious noise.  But we can see from the contours that there is some structure.  Not sure what to make of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magdata = pd.read_csv(\"mag_TMI_gascoyne.txt\", header=0)\n",
    "print magdata.Latitude.min(), magdata.Latitude.max()\n",
    "magdata = magdata[np.abs(magdata.Latitude + 24.85) < 0.015]\n",
    "magdata = magdata[np.abs(magdata.Longitude - 116.1) < 0.015]\n",
    "print magdata.grid_code.min(), magdata.grid_code.max()\n",
    "print magdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([magdata.Latitude, magdata.Longitude]).T\n",
    "Y = np.array([magdata.grid_code]).T\n",
    "kernel = GPy.kern.Matern32(2)\n",
    "print \"X.shape =\", X.shape\n",
    "print \"Y.shape =\", Y.shape\n",
    "model = GPy.models.GPRegression(X, Y, kernel)\n",
    "model.optimize(messages=True)\n",
    "fig = model.plot()\n",
    "print model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magnetism, on the other hand, has at least some non-zero Gaussian noise to it.  But surely the length scale is kind of out of whack?  And are those repeated points there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dX0 = X[:,0].reshape(36,36)[:,0]\n",
    "print dX0\n",
    "print dX0[1:] - dX0[:-1]\n",
    "dX1 = X[:,1].reshape(36,36)[1,:]\n",
    "print dX1\n",
    "print dX1[1:] - dX1[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oooh looks like they are.  Well, in a way that's useful, if those are real -- in principle they give us the noise scale.  But if it isn't real, it's not clear this would have worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ipy361]",
   "language": "python",
   "name": "conda-env-ipy361-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
