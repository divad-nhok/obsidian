{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read obsidian error logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import error_log_reader\n",
    "import function_args\n",
    "import plot_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last convergence table, rhat plot, last stats table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#curr_dir = '/Users/davidkohn/dev/obsidian/output/experiment_03_05_2018_14/'\n",
    "curr_dir = '/Users/davidkohn/dev/obsidian/output/experiments/05_29_2018/12/'\n",
    "branch = 'master' # 'asym', 'mhrw', 'adapt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if branch == 'asym':\n",
    "    line_no_converge = 260\n",
    "    line_no_stats = 250\n",
    "elif branch == 'mhrw':\n",
    "    line_no_converge = 252\n",
    "    line_no_stats = 242\n",
    "elif branch == 'adapt':\n",
    "    pass\n",
    "elif branch == 'master':\n",
    "    line_no_converge = 257\n",
    "    line_no_stats = 247\n",
    "    #line_no_converge = \n",
    "    #line_no_stats = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error log stats table\n",
    "out_stats = error_log_reader.get_info(\n",
    "    curr_dir,\n",
    "    **function_args.kwargs_statstable(line_no_stats)\n",
    ")[0]\n",
    "array_all = np.stack(out_stats, axis = 2)\n",
    "\n",
    "df = out_stats[-1]\n",
    "fpath = os.path.join(curr_dir, 'last_stats_table.csv')\n",
    "df.to_csv(fpath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last rhat table\n",
    "out_convergence = error_log_reader.get_info(\n",
    "    curr_dir,\n",
    "    **function_args.kwargs_convergence(line_no_converge)\n",
    ")[0]\n",
    "\n",
    "arr = out_convergence[-1]\n",
    "df = pd.DataFrame(\n",
    "    [np.array(list(range(len(arr)))), arr]\n",
    ").T\n",
    "df.columns = ['ChainID', 'Rhat']\n",
    "df['ChainID'] = df['ChainID'].astype(int)\n",
    "\n",
    "fpath = os.path.join(curr_dir, 'last_convergence.csv')\n",
    "df.to_csv(fpath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rhat plot\n",
    "data = out_convergence.T\n",
    "plot_functions.make_rhat_plot(data, curr_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood search\n",
    "search for lines with 'likelihood' in them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gascoyne shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = error_log_reader.get_info(\n",
    "    dir_gascoyne_01_01,\n",
    "    **function_args.kwargs_likelihood\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot likelihoods for each parameter type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 20\n",
    "xstr = 'Log likelihood'\n",
    "ystr = 'Frequency'\n",
    "title_str = 'frequency_loglikelihood_{}.png'\n",
    "fig_height = 10\n",
    "fig_width = 10\n",
    "\n",
    "for find_str in find_str_list:\n",
    "    print(find_str)\n",
    "    fig = plt.figure(figsize = (fig_width, fig_height))\n",
    "    for shard in out_likelihoods:\n",
    "        x = shard[find_str]\n",
    "        if x:\n",
    "            plt.hist(x)\n",
    "    plt.xlabel(\n",
    "        xstr,\n",
    "        fontsize = fontsize\n",
    "    )\n",
    "    plt.ylabel(\n",
    "        ystr,\n",
    "        fontsize = fontsize\n",
    "    )\n",
    "    plt.title(\n",
    "        find_str,\n",
    "        fontsize = fontsize\n",
    "    )\n",
    "    plt.savefig(title_str.format(find_str.replace(' ', '-')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence info search\n",
    "search for lines with convergence info in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recast time strings as datetime objects -> not being used at the moment\n",
    "\"\"\"regex = '([0-9][0-9]:[0-9][0-9]:[0-9][0-9]\\.[0-9]+)'\n",
    "new_time_list = [\n",
    "    datetime.datetime.strptime((re.findall(regex, time_line)[0]), '%H:%M:%S.%f').time()\n",
    "    for time_line in time_list\n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_convergence = error_log_reader.get_info(\n",
    "    curr_dir,\n",
    "    **function_args.kwargs_convergence\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = out_convergence[-1]\n",
    "df = pd.DataFrame(\n",
    "    [np.array(list(range(len(arr)))), arr]\n",
    ").T\n",
    "df.columns = ['ChainID', 'Rhat']\n",
    "df['ChainID'] = df['ChainID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(curr_dir, 'last_convergence.csv')\n",
    "df.to_csv(fpath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = out_convergence.T\n",
    "param_range = c.shape[0]\n",
    "\n",
    "fig_width = 10\n",
    "fig_height = 10\n",
    "xstr = 'Rhat bin'\n",
    "ystr = 'Frequency'\n",
    "title_str = 'Histogram of rhat for all chains'\n",
    "save_str = 'rhat_histogram'\n",
    "fontsize = 20\n",
    "\n",
    "fig = plt.figure(\n",
    "    figsize = (fig_width, fig_height)\n",
    ")\n",
    "\n",
    "ax = fig.gca()\n",
    "y = c[:, -1]\n",
    "plt.hist(y)\n",
    "\n",
    "plt.xlabel(\n",
    "    xstr,\n",
    "    fontsize = fontsize\n",
    ")\n",
    "plt.ylabel(\n",
    "    ystr,\n",
    "    fontsize = fontsize\n",
    ")\n",
    "plt.title(\n",
    "    title_str,\n",
    "    fontsize = fontsize\n",
    ")\n",
    "out_path = os.path.join(\n",
    "    curr_dir, \n",
    "    save_str\n",
    ")\n",
    "plt.savefig(\n",
    "    out_path\n",
    ")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_width = 20\n",
    "fig_height = 20\n",
    "xstr = 'MCMC iteration'\n",
    "ystr = 'Rhat'\n",
    "title_str = 'Rhat over MCMC iterations for all chains'\n",
    "save_str = 'rhat_iterations'\n",
    "fontsize = 20\n",
    "start_slice_idx = 100\n",
    "\n",
    "fig = plt.figure(\n",
    "    figsize = (fig_width, fig_height)\n",
    ")\n",
    "ax = fig.gca()\n",
    "for param_idx in range(param_range):\n",
    "    y = c[param_idx,:]\n",
    "    y = y[~np.isnan(y)]\n",
    "    x = range(len(y))\n",
    "    idx = slice(start_slice_idx, len(y))\n",
    "    plt.plot(x[idx], y[idx])\n",
    "    \n",
    "plt.xlabel(\n",
    "    xstr,\n",
    "    fontsize = fontsize\n",
    ")\n",
    "plt.ylabel(\n",
    "    ystr,\n",
    "    fontsize = fontsize\n",
    ")\n",
    "plt.title(\n",
    "    title_str,\n",
    "    fontsize = fontsize\n",
    ")\n",
    "out_path = os.path.join(\n",
    "    curr_dir, \n",
    "    save_str\n",
    ")\n",
    "plt.savefig(\n",
    "    out_path\n",
    ")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_functions.make_convergence_plot(\n",
    "    c, \n",
    "    save_dir = curr_dir,\n",
    "    param_range = param_range\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats table search\n",
    "search for the stats table\n",
    "the stats table contains the following info:\n",
    "    0. ChainID\n",
    "    1. Length - no. samples\n",
    "    2. MinEngy - lowest energy\n",
    "    3. CurrEngy - last state\n",
    "    4. Sigma - proposal width\n",
    "    5. AcptRt\n",
    "    6. GlbAcptRt\n",
    "    7. Beta - inverse temperature of the chain when this state was recorded\n",
    "        - from obsidian/src/infer/mcmctypes.hpp\n",
    "    8. SwapRt\n",
    "    9.GlbWapRt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_stats = error_log_reader.get_info(\n",
    "    curr_dir,\n",
    "    **function_args.kwargs_statstable\n",
    ")[0]\n",
    "array_all = np.stack(out_stats, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = out_stats[-1]\n",
    "fpath = os.path.join(curr_dir, 'last_stats_table.csv')\n",
    "df.to_csv(fpath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array_all = np.stack(out_stats, axis = 2)\n",
    "vals = array_all[3, 8, :]\n",
    "plt.plot(vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_stats = error_log_reader.get_info(\n",
    "    dir_adaptive_test,\n",
    "    **function_args.kwargs_statstable2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_all = np.stack(out_stats[0], axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_stats[0][0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 1\n",
    "array_all[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = array_all[0, 4, :]\n",
    "plt.plot(vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = array_all[1, 4, :]\n",
    "plt.plot(vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = array_all[2, 4, :]\n",
    "plt.plot(vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cooper basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recast time strings as datetime objects -> unused for now\n",
    "\"\"\"new_time_list = [\n",
    "    error_log_reader.extract_time_from_string(time_line)\n",
    "    for time_line in time_list\n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average evaluation time search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_evaltime = error_log_reader.get_info(\n",
    "    curr_dir,\n",
    "    **function_args.kwargs_evaluationtime\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_evaltime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xstr = 'Forward model and likelihood average evaluation time in milliseconds'\n",
    "ystr = 'Frequency'\n",
    "title_str = 'Histogram of average evaluation time for sensor {}'\n",
    "save_str = 'sensor-eval-time-{}.png'\n",
    "fontsize = 20\n",
    "fig_width = 10\n",
    "fig_height = 10\n",
    "save_dir = curr_dir\n",
    "for key in out_evaltime[0].keys():\n",
    "    plot_data = []\n",
    "    for sub_dict in out_evaltime:\n",
    "        plot_data += sub_dict[key]\n",
    "    fig = plt.figure(figsize=(fig_width,fig_height))\n",
    "    plt.hist(plot_data)\n",
    "    plt.xlabel(\n",
    "        xstr,\n",
    "        fontsize = fontsize\n",
    "    )\n",
    "    plt.ylabel(\n",
    "        ystr,\n",
    "        fontsize = fontsize\n",
    "    )\n",
    "    plt.title(\n",
    "        title_str.format(key),\n",
    "        fontsize = fontsize\n",
    "    )\n",
    "    out_path = os.path.join(save_dir, save_str.format(key))\n",
    "    plt.savefig(\n",
    "        out_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ipy361]",
   "language": "python",
   "name": "conda-env-ipy361-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
