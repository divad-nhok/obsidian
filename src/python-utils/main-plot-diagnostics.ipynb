{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from plotting_functions import autocorrelation_plot\n",
    "from plotting_functions import \\\n",
    "run_diagnostic_plots, plot_acf, plot_trace, plot_sensor_output, \\\n",
    "get_fname_list, plot_layer_posteriors, plot_fieldobs, plot_hist_diagnostic, make_chainstat_table, \\\n",
    "make_chains\n",
    "import plotting_functions\n",
    "import visvis as vv\n",
    "import diagplots2\n",
    "import pymc3\n",
    "import matplotlib\n",
    "\n",
    "import geovis_notebook_version\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## last stats table for temperature ladder\n",
    "- note to generate the last_stats_table.csv I opened the obsidian.pbs.e* file on the HPC and copied a converged stats table out to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_stats_table = '/Volumes/david_hd/obsidian/output/experiments/11_15_2018/01/last_stats_table.csv'\n",
    "stacks = 4\n",
    "chains = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(fpath_stats_table,sep='\\s+')\n",
    "total = stacks * chains + 1\n",
    "start_list = np.arange(0, total - chains, chains)\n",
    "stop_list = np.arange(chains, total, chains)\n",
    "print(start_list, stop_list)\n",
    "df_stack_index_list = [\n",
    "    range(start_i,stop_i) for start_i, stop_i in zip(start_list, stop_list)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stack_list = [df.loc[l,:] for l in df_stack_index_list]\n",
    "for df_stack in df_stack_list:\n",
    "    assert(df_stack.shape[0] == chains)\n",
    "    #assert(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.abs(df_stack_list[1].diff(axis = 0))['Beta'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [df_stack['Beta'].values for df_stack in df_stack_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = plt.gca()\n",
    "x = list(range(1,13))\n",
    "for y in data:\n",
    "    plt.plot(x, np.log(y))\n",
    "    ax.set_xticks(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = df_list[0].loc[1:11,'Beta'].values\n",
    "denom = df_list[0].loc[0:10,'Beta'].values\n",
    "data = denom/num\n",
    "print(data)\n",
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author = 'dk' # 'dk' or 'rs\n",
    "\n",
    "rp_param_title_list = ['Rock density', 'Magnetic susceptibility']\n",
    "#rp_layer_title_list = ['Layer 0', 'Layer 1']\n",
    "rp_layer_title_list = ['Halfway Gneiss', 'Durlacher Supersuite']\n",
    "\n",
    "if author == 'dk': # user input - for david's results\n",
    "    dir_parent = '/Volumes/david_hd/obsidian/output/experiments/'\n",
    "    dir_output_diagnostics = 'output/plots-diagnostic'\n",
    "    dir_output_sensors = 'output/plots-sensors'\n",
    "    fname_samples = 'output0.npz'\n",
    "\n",
    "    dir_year = '2018'\n",
    "    dir_month = '11'\n",
    "    dir_day = '15'\n",
    "    exp_str = '{}_{}_{}'.format(dir_month, dir_day, dir_year)\n",
    "    num_list = ['01']\n",
    "\n",
    "    param_key_list = [\n",
    "        'layer0rockProperties',\n",
    "        'layer1rockProperties'\n",
    "    ]\n",
    "    param_idx_list = [0, 1]\n",
    "\n",
    "    plot_function_list = [\n",
    "        plot_acf,\n",
    "        plot_trace,\n",
    "        plot_hist_diagnostic,\n",
    "        make_chainstat_table\n",
    "    ]\n",
    "\n",
    "    plot_function_names = [\n",
    "        'acf',\n",
    "        'trace',\n",
    "        'hist',\n",
    "        'chainstat-table',\n",
    "    ]\n",
    "    extension_list = [\n",
    "        'eps',\n",
    "        'eps',\n",
    "        'eps',\n",
    "        'csv',\n",
    "    ]\n",
    "    # for sensor plot output\n",
    "    sensor_name_list = ['grav', 'mag'] #'grav' or 'mag'\n",
    "\n",
    "    data_names_list = [\n",
    "        'magSensors','magReadings','gravSensors','gravReadings'\n",
    "    ]\n",
    "    xp = lambda exp_str, num: os.path.join(exp_str, num)\n",
    "\n",
    "elif author == 'rs': # user input - for richard's results\n",
    "    dir_parent = '/Volumes/david_hd/obsidian/output/experiments/'\n",
    "    dir_output_diagnostics = 'output/plots-diagnostic'\n",
    "    dir_output_sensors = 'output/plots-sensors'\n",
    "    #fname_samples = 'gascoyne_v4.npz'\n",
    "\n",
    "    exp_str = 'gascoyne_v5_run'\n",
    "    fname_samples = 'gascoyne_v5-rs-run03-thin1000.npz'\n",
    "    #fname_samples = 'output.npz'\n",
    "    #num_list = ['01', '02', '03', '04', '05', '06']\n",
    "    num_list = ['03']\n",
    "\n",
    "    param_key_list = [\n",
    "        'layer0rockProperties',\n",
    "        'layer1rockProperties'\n",
    "    ]\n",
    "    param_idx_list = [0, 1]\n",
    "\n",
    "    plot_function_list = [\n",
    "        plot_acf,\n",
    "        plot_trace,\n",
    "        plot_hist_diagnostic,\n",
    "        make_chainstat_table\n",
    "    ]\n",
    "\n",
    "    plot_function_names = [\n",
    "        'acf',\n",
    "        'trace',\n",
    "        'hist',\n",
    "        'chainstat-table'\n",
    "    ]\n",
    "    extension_list = [\n",
    "        'eps',\n",
    "        'eps',\n",
    "        'eps',\n",
    "        'csv',\n",
    "    ]\n",
    "    # for sensor plot output\n",
    "    sensor_name_list = ['grav', 'mag'] #'grav' or 'mag'\n",
    "\n",
    "    data_names_list = [\n",
    "        'magSensors','magReadings','gravSensors','gravReadings'\n",
    "    ]\n",
    "    xp = lambda exp_str, num: exp_str + num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnostic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put together file paths\n",
    "if author == 'dk':\n",
    "    fpath_in_list = [\n",
    "        os.path.join(dir_parent, exp_str, num, fname_samples)\n",
    "        for num in num_list\n",
    "    ]\n",
    "    dir_out_list = [\n",
    "        os.path.join(dir_parent, exp_str, num, dir_output_diagnostics)\n",
    "        for num in num_list\n",
    "    ]\n",
    "elif author == 'rs':\n",
    "    fpath_in_list = [\n",
    "        os.path.join(dir_parent, exp_str + num, fname_samples)\n",
    "        for num in num_list\n",
    "    ]\n",
    "    dir_out_list = [\n",
    "        os.path.join(dir_parent, exp_str + num, dir_output_diagnostics)\n",
    "        for num in num_list\n",
    "    ]\n",
    "print(fpath_in_list)\n",
    "print(dir_out_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer_title_list = ['Layer 0', 'Layer 1']\n",
    "layer_title_list = ['Halfway Gneiss', 'Durlacher Supersuite']\n",
    "param_title_list = ['Rock density', 'Magnetic susceptibility']\n",
    "#stack_length_list = [1160161, 1154009, 1129264, 1111255]\n",
    "stack_length_list = [1592406, 1551447, 1567431, 1555443, 1566432, 1593405]\n",
    "n_burn = 0\n",
    "n_thin = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make plots\n",
    "run_diagnostic_plots(\n",
    "    fpath_in_list,\n",
    "    dir_out_list,\n",
    "    param_key_list,\n",
    "    param_idx_list,\n",
    "    plot_function_list,\n",
    "    extension_list,\n",
    "    plot_function_names,\n",
    "    layer_title_list,\n",
    "    param_title_list,\n",
    "    n_burn = n_burn,\n",
    "    n_thin = n_thin,\n",
    "    stack_length_list = stack_length_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnostic hist testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment_idx, (fpath_in, dir_out) in enumerate(zip(fpath_in_list, dir_out_list)):\n",
    "    if not os.path.isdir(dir_out):\n",
    "        os.makedirs(dir_out)\n",
    "    if os.path.exists(fpath_in):\n",
    "        samples_i = np.load(fpath_in)\n",
    "        for layer_idx, layer in enumerate(param_key_list):\n",
    "            layer_params = samples_i[layer]\n",
    "            layer_title = layer\n",
    "            if layer_title_list:\n",
    "                layer_title = layer_title_list[layer_idx]\n",
    "            for param_idx in param_idx_list:\n",
    "                param = layer_params[:, param_idx]\n",
    "                if np.any(stack_length_list):\n",
    "                    param = make_chains(param, stack_length_list, n_burn, n_thin, make_uniform_length = False)\n",
    "                param_title = 'param {}'.format(param_title_list[param_idx])\n",
    "                if param_title_list:\n",
    "                    param_title = param_title_list[param_idx].lower()\n",
    "                fname_fig_param = '{}-param{}'.format(layer,param_idx)\n",
    "                plot_func = test_hist\n",
    "                plot_func_name = 'hist'\n",
    "                extension = 'eps'\n",
    "                fname_fig = '{}-{}.{}'.format(plot_func_name, fname_fig_param, extension)\n",
    "                dir_out = '/Users/davidkohn/Desktop'\n",
    "                fpath_out = os.path.join(dir_out, fname_fig)\n",
    "                plot_title = '{} {}'.format(layer_title, param_title)\n",
    "                #print('param.shape: {}'.format(param.shape))\n",
    "                data = param[n_burn:]\n",
    "                #print('data.shape: {}'.format(data.shape))\n",
    "                plot_func(\n",
    "                    param[n_burn:], \n",
    "                    fpath_out = fpath_out, \n",
    "                    plot_title = plot_title\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_i['layer1rockProperties'][:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_i['layer1rockProperties'][:,1].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(samples_i['layer1rockProperties'][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [\n",
    "    2.7022, -3.6325, 2.6972, -3.5178\n",
    "]\n",
    "variances = [\n",
    "    0.0260, 0.1297, 0.006, 0.6044\n",
    "]\n",
    "x_labels1 = [\n",
    "    2.55 , -4.30, 2.50, -2.75\n",
    "]\n",
    "# layer 0 density\n",
    "\"\"\"for layer_mean, layer_var in zip(means, variances):\n",
    "    for param_mean, param_var, in zip(layer_mean, layer_var):\n",
    "        print(param_mean - np.sqrt(param_var), param_mean + np.sqrt(param_var))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plt.rc('text', usetex = True)\n",
    "    plt.rc('font', family = 'serif')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for experiment_idx, (fpath_in, dir_out) in enumerate(zip(fpath_in_list, dir_out_list)):\n",
    "    if not os.path.isdir(dir_out):\n",
    "        os.makedirs(dir_out)\n",
    "    if os.path.exists(fpath_in):\n",
    "        samples_i = np.load(fpath_in)\n",
    "        idx = 0\n",
    "        for layer_idx, layer in enumerate(param_key_list):\n",
    "            layer_params = samples_i[layer]\n",
    "            layer_title = layer\n",
    "            if layer_title_list:\n",
    "                layer_title = layer_title_list[layer_idx]\n",
    "            for param_idx in param_idx_list:\n",
    "                param = layer_params[:, param_idx]\n",
    "                if np.any(stack_length_list):\n",
    "                    param = make_chains(param, stack_length_list, n_burn, n_thin, make_uniform_length = False)\n",
    "                param_title = 'param {}'.format(param_title_list[param_idx])\n",
    "                if param_title_list:\n",
    "                    param_title = param_title_list[param_idx].lower()\n",
    "                fname_fig_param = '{}-param{}'.format(layer,param_idx)\n",
    "                plot_func = test_trace\n",
    "                plot_func_name = 'trace'\n",
    "                extension = 'eps'\n",
    "                fname_fig = '{}-{}.{}'.format(plot_func_name, fname_fig_param, extension)\n",
    "                if param_title == 'rock density':\n",
    "                    print('test')\n",
    "                    ylabel = 'Density ($g$ cm$^{-3}$)'\n",
    "                elif param_title == 'magnetic susceptibility':\n",
    "                    ylabel = 'Log susceptibility ($T$ cm$^{-9}$)'\n",
    "\n",
    "                dir_out = '/Users/davidkohn/Desktop'\n",
    "                fpath_out = os.path.join(dir_out, fname_fig)\n",
    "                plot_title = '{} {}'.format(layer_title, param_title)\n",
    "                #print('param.shape: {}'.format(param.shape))\n",
    "                data = param[n_burn:]\n",
    "                #print('data.shape: {}'.format(data.shape))\n",
    "                print( x_labels1[idx])\n",
    "                plot_func(\n",
    "                    param[n_burn:], \n",
    "                    fpath_out = fpath_out, \n",
    "                    plot_title = plot_title,\n",
    "                    y_label = ylabel,\n",
    "                    mean_i = means[idx],\n",
    "                    var_i = variances[idx],\n",
    "                    x_label_ax1_loc = x_labels1[idx]\n",
    "                )\n",
    "                idx += 1\n",
    "                #break\n",
    "            #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_trace makes a combined trace-histogram plot\n",
    "def test_trace(\n",
    "    data,\n",
    "    img_format = 'png',\n",
    "    fpath_out = None,\n",
    "    plot_title = None,\n",
    "    thin_amount = None,\n",
    "    lw = 0.5,\n",
    "    y_label = 'Parameter Value',\n",
    "    fontsize=20,\n",
    "    mean_i = 0,\n",
    "    var_i = 0,\n",
    "    x_label_ax1_loc = None\n",
    "):\n",
    "    try:\n",
    "        plt.rc('text', usetex = True)\n",
    "        plt.rc('font', family = 'serif')\n",
    "    except:\n",
    "        pass\n",
    "    x_label = 'Sample Number (thinned $\\\\times 1000$)'\n",
    "    if thin_amount:\n",
    "        x_label = 'MCMC iteration (thinned $\\\\times {}$)'.format(thin_amount)\n",
    "    #f = plt.figure(figsize = (fig_width, fig_height))\n",
    "    #f, axes = plt.subplots(4, 2, figsize=(5,5))\n",
    "    f, axes = plt.subplots(len(data), 3)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    #print(axes)\n",
    "    data = [plotting_functions.reject_outliers(data_i) for data_i in data]\n",
    "    data_max = np.max(np.concatenate(data))\n",
    "    data_min = np.min(np.concatenate(data))\n",
    "    #print(data_min)\n",
    "    prior_lower = mean_i - np.sqrt(var_i)\n",
    "    #print(prior_lower)\n",
    "    prior_upper = mean_i + np.sqrt(var_i)\n",
    "    if prior_lower < data_min: \n",
    "        #print('setting data_min')\n",
    "        data_min = prior_lower + prior_lower * 0.01\n",
    "        #print(data_min)\n",
    "    for idx, (data_i, ax) in enumerate(zip(data, axes)):\n",
    "        ax1, ax2, ax3 = ax\n",
    "        # axis2 is histogram/density plot\n",
    "        _ = sns.kdeplot(data_i, ax = ax2, color='black', lw=0.5)\n",
    "        _ = ax2.axvline(np.mean(data_i), color='blue', lw=0.5)\n",
    "        _ = ax2.axvline(np.percentile(data_i, 95), color='red', ls='dashed', lw=0.5)\n",
    "        _ = ax2.axvline(np.percentile(data_i, 5), color='red', ls='dashed', lw=0.5)\n",
    "        #print(mean_i, var_i)\n",
    "        #_ = ax2.axvline(mean_i - 2 * np.sqrt(var_i), color='green', ls='dashed', lw=0.5)\n",
    "        #_ = ax2.axvline(mean_i + 2 * np.sqrt(var_i), color='green', ls='dashed', lw=0.5)\n",
    "        #_ = ax2.set_xlim([data_min, data_max])\n",
    "        \n",
    "        # axis1 is trace plot\n",
    "        _ = ax1.plot(data_i, linewidth = lw, color='black', lw=0.5)\n",
    "        _ = ax1.axhline(np.mean(data_i), color='blue', lw=0.5)\n",
    "        _ = ax1.axhline(np.percentile(data_i, 97.5), color='red', ls='dashed', lw=0.5)\n",
    "        _ = ax1.axhline(np.percentile(data_i, 2.5), color='red', ls='dashed', lw=0.5)\n",
    "        \n",
    "        # axis3 is acf plot\n",
    "        _ = autocorrelation_plot(data_i, ax = ax3)\n",
    "        plt.setp(ax3.lines, linewidth = 0.5)\n",
    "\n",
    "        # x axis\n",
    "        \"\"\"\n",
    "        start = 0\n",
    "        end = np.max(data_i)\n",
    "        middle = (end - start) / 2\n",
    "        new_xt = [start, middle, end]\n",
    "        ax3.set_xticks(new_xt)\n",
    "        ax3.set_xticklabels([int(num) for num in new_xt])\n",
    "        ax3.set_xlim([start, end])\n",
    "        _ = plt.xticks(fontsize = fontsize)\n",
    "        _ = plt.xlabel(x_label, fontsize = fontsize)\n",
    "        \"\"\"\n",
    "\n",
    "        # y axis\n",
    "        #start = np.min([np.min(line.get_ydata()) for line in ax3.lines])\n",
    "        end = np.around(np.max([np.max(line.get_ydata()) for line in ax3.lines]), decimals = 2)\n",
    "        #middle = (end + start) / 2\n",
    "        #new_yt = [start, middle, end]\n",
    "        #new_yt = np.around(new_yt, decimals = 2)\n",
    "        #new_yt = np.append(new_yt,0)\n",
    "        #new_yt = np.sort(new_yt)\n",
    "        new_yt = [0.1, end]\n",
    "        ax3.set_yticks(new_yt)\n",
    "        ax3.set_yticklabels(new_yt)\n",
    "        ax3.yaxis.tick_right()\n",
    "        #_ = plt.ax3(fontsize = fontsize)\n",
    "        #_ = plt.ylabel(y_label, fontsize = fontsize)\n",
    "        \n",
    "        \n",
    "        yticks = [np.percentile(data_i, 2.5), np.mean(data_i), np.percentile(data_i, 97.5)]\n",
    "        yticklabels = ['{:.2f}'.format(yt_i) for yt_i in yticks]\n",
    "        _ = ax1.set_yticks(yticks)\n",
    "        _ = ax1.set_yticklabels(yticklabels)\n",
    "        yt = [np.mean(data_i)]\n",
    "        ytl = ['{:.2f}'.format(yt_i) for yt_i in yt]\n",
    "        print(yt, ytl)\n",
    "        _ = ax2.set_yticks([])\n",
    "        _ = ax2.set_yticklabels([])\n",
    "        if idx != len(data) - 1:\n",
    "            _ = ax1.set_xticks([])\n",
    "            _ = ax1.set_xticklabels([])\n",
    "            _ = ax2.set_xticks([])\n",
    "            _ = ax2.set_xticklabels([])\n",
    "            _ = ax3.set_xticks([])\n",
    "            _ = ax3.set_xticklabels([])\n",
    "        else:\n",
    "            #ax1.text(500,x_label_ax1_loc,'MCMC Sample', fontsize=15)\n",
    "            label_fontsize = 10\n",
    "            ax1.set_xlabel('MCMC Sample', fontsize=label_fontsize)\n",
    "            ax2.set_xlabel(y_label, fontsize=label_fontsize)\n",
    "            ax3.set_xlabel('MCMC Sample', fontsize=label_fontsize)\n",
    "            \n",
    "            ax1.set_xticks([1, len(data_i)])\n",
    "            ax2_xticks = [np.percentile(data_i, 5), np.mean(data_i), np.percentile(data_i, 95)]\n",
    "            ax2_xtick_labels = [np.around(xti, decimals=2) for xti in ax2_xticks]\n",
    "            ax2.set_xticks(ax2_xticks)\n",
    "            ax2.set_xticklabels(ax2_xtick_labels)\n",
    "            ax3.set_xticks([1, len(data_i)])\n",
    "\n",
    "    #f.text(0.04, 0.5, y_label, va='center', rotation='vertical')\n",
    "    f.text(0.05, 0.9020, y_label, va='center', fontsize = label_fontsize)\n",
    "    f.text(0.35, 0.9020, 'Density', va='center', fontsize = label_fontsize)\n",
    "    f.text(0.625, 0.9020, 'Autocorrelation', va='center', fontsize = label_fontsize)\n",
    "\n",
    "    if plot_title: f.suptitle(plot_title.title(), fontsize = fontsize)\n",
    "    #plt.tight_layout()\n",
    "    plt.savefig(fpath_out)\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "def test_hist(\n",
    "    data,\n",
    "    fpath_out,\n",
    "    plot_title = None,\n",
    "    fig_width = 5,\n",
    "    fig_height = 5,\n",
    "    bins = 10,\n",
    "    width = 0.1,\n",
    "    tick_fontsize = 20,\n",
    "    xlab = 'Parameter bin value',\n",
    "    mean_labels = True,\n",
    "    mean_line = True,\n",
    "    xlabels = [],\n",
    "    fontsize = 20,\n",
    "\n",
    "):\n",
    "    data_list = [plotting_functions.reject_outliers(data_i) for data_i in data]\n",
    "    colors = ['red', 'green', 'blue', 'orange']\n",
    "    colors = [matplotlib.colors.to_rgba(color, alpha=0.5) for color in colors]\n",
    "    #colors = [(1,0,0,0.5), (0,1,0,0.5), (0,0,1,0.5), (1,215/255,0,0.5)]\n",
    "    idx = 0\n",
    "    fig = plt.figure(figsize=(fig_width, fig_height))\n",
    "    ax = plt.gca()\n",
    "    yd_list = []\n",
    "    for data_i in data_list:\n",
    "        weights = np.ones_like(data_i)/float(len(data_i))\n",
    "        \"\"\"h = plt.hist(\n",
    "            data_i, \n",
    "            bins = bins, \n",
    "            weights = weights,\n",
    "            fc = colors[idx],\n",
    "            ec='black',\n",
    "        )\"\"\"\n",
    "        _ = sns.kdeplot(data_i)\n",
    "        idx += 1\n",
    "    yd = [line.get_ydata() for line in ax.get_lines()]\n",
    "    yd_list.append(yd)\n",
    "    yd = np.array(yd_list)\n",
    "    mini = np.min([np.min(data_i) for data_i in data_list])\n",
    "    maxi = np.max([np.max(data_i) for data_i in data_list])\n",
    "    mean = np.mean([np.mean(data_i) for data_i in data_list])\n",
    "    xt = [mini, mean, maxi]\n",
    "    xtl = ['{:.2f}'.format(xt_i) for xt_i in xt]\n",
    "    _ = plt.xlabel(xlab, fontsize = fontsize)\n",
    "    _ = plt.ylabel('Density', fontsize = fontsize)\n",
    "    _ = plt.xticks(xt, fontsize = tick_fontsize)\n",
    "    _ = ax.set_xticklabels(xtl)\n",
    "    #yt = ax.get_yticks()[1:]\n",
    "    yt = [0, (np.max(yd))/2, np.max(yd)]\n",
    "    ytl = ['{:.2f}'.format(yt_i) for yt_i in yt]\n",
    "    _ = plt.yticks(yt, fontsize = tick_fontsize)\n",
    "    _ = ax.set_yticklabels(ytl)\n",
    "    if plot_title:\n",
    "        _ = plt.title(plot_title, fontsize = fontsize)\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    plt.savefig(fpath_out)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensor plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put together file paths\n",
    "#subsample_csv = False\n",
    "#fname_samples = 'output.npz'\n",
    "#fname_samples = 'gascoyne_v5-rs-run02-thin1000.npz'\n",
    "\n",
    "data_names_list_sensorplots = data_names_list\n",
    "#data_names_list_sensorplots = ['magSensors_subsamp', 'magReadings_subsamp', 'gravSensors', 'gravReadings']\n",
    "#data_names_list_sensorplots = ['magSensors_rndsub', 'magReadings_rndsub', 'gravSensors_rndsub', 'gravReadings_rndsub']\n",
    "\n",
    "fpath_samples_list = [\n",
    "    os.path.join(dir_parent, xp(exp_str, num), fname_samples)\n",
    "    for num in num_list\n",
    "]\n",
    "\n",
    "fpath_csv_list = [\n",
    "    [\n",
    "        os.path.join(dir_parent, xp(exp_str, num), \"{}\".format(data_name) + \".csv\")\n",
    "        for data_name in data_names_list_sensorplots\n",
    "    ]\n",
    "    for num in num_list\n",
    "]\n",
    "\n",
    "fieldobs_names_list = ['fieldobsSensors', 'fieldobsReadings']\n",
    "fpath_fieldobs_csv_list = [\n",
    "    [\n",
    "        os.path.join(dir_parent, xp(exp_str, num), \"{}\".format(data_name) + \".csv\")\n",
    "        for data_name in fieldobs_names_list\n",
    "    ]\n",
    "    for num in num_list\n",
    "]\n",
    "\n",
    "dir_out_list = [\n",
    "    os.path.join(dir_parent, xp(exp_str, num), dir_output_sensors)\n",
    "    for num in num_list\n",
    "]\n",
    "print(dir_out_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_sensor_output(fpath_samples_list, dir_out_list, fpath_csv_list, data_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors, readings = plot_fieldobs(\n",
    "    fpath_samples_list, dir_out_list, fpath_fieldobs_csv_list, fieldobs_names_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing histograms of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plt.rc('text', usetex = True)\n",
    "    plt.rc('font', family = 'serif')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mag_sensors = pd.read_csv('/Volumes/david_hd/obsidian/output/experiments/11_15_2018/01/magSensors.csv', names=['x', 'y'], comment='#')\n",
    "mag_actual = pd.read_csv('/Volumes/david_hd/obsidian/output/experiments/11_15_2018/01/magReadings.csv', comment='#', header=None)\n",
    "grav_actual = pd.read_csv('/Volumes/david_hd/obsidian/output/experiments/11_15_2018/01/gravReadings.csv', comment='#', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mag_actual.values\n",
    "data = grav_actual.values\n",
    "n = data.shape[0]\n",
    "f = plt.figure(figsize=(5,5))\n",
    "ax = plt.gca()\n",
    "weights = np.ones((n,1))/n\n",
    "plt.hist(\n",
    "    data, bins = 20, weights = weights, fill=None\n",
    ")\n",
    "\n",
    "mean = np.mean(data)\n",
    "plt.axvline(mean,c='red')\n",
    "\n",
    "\"\"\"yt = ax.get_yticks()[1:-1]\n",
    "ytl = ['{:.0f}\\%'.format(yt_i * 100) for yt_i in yt]\n",
    "_ = ax.set_yticks(yt)\n",
    "_ = ax.set_yticklabels(ytl)\n",
    "\n",
    "xt = ax.get_xticks()[1:-1]\n",
    "xtl = ['{:.0f}\\%'.format(xt_i * 100) for xt_i in xt]\n",
    "_ = ax.set_xticks(xt)\n",
    "_ = ax.set_xticklabels(xtl)\"\"\"\n",
    "\n",
    "_ = plt.xlabel('Mag')\n",
    "_ = plt.ylabel('Probability')\n",
    "#plt.savefig('/Users/davidkohn/Desktop/fieldobs-p.eps')\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fieldobs confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([actual, predicted], index=['actual', 'predicted']).T\n",
    "not_missing_idx = df['actual'] != -1\n",
    "df = df.loc[not_missing_idx, :].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0, 1]\n",
    "cnf = confusion_matrix(df['actual'], df['predicted'])\n",
    "df_cnf = pd.DataFrame(cnf, columns=labels, index=labels)\n",
    "df_cnf.index.name = 'True label'\n",
    "df_cnf.columns.name = 'Predicted label'\n",
    "df_cnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = df_cnf.loc[1,1]\n",
    "tn = df_cnf.loc[0,0]\n",
    "fn = df_cnf.loc[0,1]\n",
    "fp = df_cnf.loc[1,0]\n",
    "sensitivity = tn/(tn + fp)\n",
    "specificity = tp/(tp + fn)\n",
    "precision = tp/(tp + fp)\n",
    "print(sensitivity, specificity, precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "# true positive / total positives\n",
    "print(sklearn.metrics.precision_score(df['actual'], df['predicted']))\n",
    "# true positive / (true pos + false neg)\n",
    "print(sklearn.metrics.recall_score(df['actual'], df['predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnf.to_csv('/Users/davidkohn/Desktop/confusion_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional fieldobs plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = fpath_samples_list[0]\n",
    "fpath = '/Volumes/david_hd/obsidian/output/experiments/11_15_2018/01/output0.npz'\n",
    "print(fpath)\n",
    "samples = np.load(fpath)\n",
    "sensors = pd.read_csv('/Volumes/david_hd/obsidian/output/experiments/11_15_2018/01/fieldobsSensors.csv', names=['x', 'y'], comment='#')\n",
    "actual = pd.read_csv('/Volumes/david_hd/obsidian/output/experiments/11_15_2018/01/fieldobsReadings.csv', comment='#', header=None)\n",
    "fr = samples['fieldReadings']\n",
    "valid_bool = (actual.values != -1).flatten()\n",
    "actual = actual[valid_bool].values\n",
    "sensors = sensors.loc[valid_bool, :].reset_index(drop=True)\n",
    "fr = fr[:,valid_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fr.shape)\n",
    "print(sensors.shape)\n",
    "print(actual.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = fr.shape[0]\n",
    "fr_uncertainty = fr.sum(axis = 0)/n\n",
    "#fr_uncertainty = (fr.T - actual).T.sum(axis=0)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fr.shape)\n",
    "print(actual.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = ['Halfway Gneiss', 'Durlacher Supersuite']\n",
    "layer_dict = {\n",
    "    0: 'Halfway Gneiss',\n",
    "    1: 'Durlacher Supersuite'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fieldobs uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 20\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = plt.gca()\n",
    "color_data = fr_uncertainty * 100\n",
    "color_data = np.round(fr_uncertainty,2) * 100\n",
    "markers = ['o', '*']\n",
    "marker_idx = 0\n",
    "for unq in np.unique(actual):\n",
    "    unq_bool = (actual == unq).flatten()\n",
    "    plt.scatter(\n",
    "        sensors.loc[unq_bool, 'x'].values, sensors.loc[unq_bool,'y'].values,\n",
    "        c = color_data[unq_bool],\n",
    "        marker=markers[marker_idx],\n",
    "        vmin=0,vmax=100,label=layer_dict[unq],edgecolor='black',linewidth=0.1,\n",
    "    )\n",
    "    marker_idx+=1\n",
    "\n",
    "ax.set_xlabel('Eastings (km)',fontsize=fontsize)\n",
    "ax.set_ylabel('Northings (km)',fontsize=fontsize)\n",
    "\n",
    "leg = ax.legend()\n",
    "leg.legendHandles[0].set_color('white')\n",
    "leg.legendHandles[0].set_edgecolor('black')\n",
    "leg.legendHandles[0].set_linewidth(0.5)\n",
    "leg.legendHandles[1].set_color('white')\n",
    "leg.legendHandles[1].set_edgecolor('black')\n",
    "leg.legendHandles[1].set_linewidth(0.5)\n",
    "\n",
    "cbt = [0, 50, 100]\n",
    "cbtl = ['{}\\%'.format(cbt_i) for cbt_i in cbt]\n",
    "cb = plt.colorbar(ticks = cbt)\n",
    "cb.set_ticklabels(cbtl)\n",
    "cb.ax.tick_params(labelsize=fontsize)\n",
    "cb.set_label('Durlacher Supersuite \\% Certainty',fontsize=fontsize)\n",
    "\n",
    "\n",
    "ticks = [0, 7500, 15000]\n",
    "tick_labels = [\n",
    "    '{:.0f}'.format(tick/1000) if float(tick/1000).is_integer()\n",
    "    else '{:.1f}'.format(tick/1000)\n",
    "    for tick in ticks\n",
    "]\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_yticklabels(tick_labels,fontsize=fontsize)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels(tick_labels,fontsize=fontsize)\n",
    "\n",
    "ax.set_xlim(0, 15000)\n",
    "ax.set_ylim(0, 15000)\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('/Users/davidkohn/Desktop/fieldobs-uncertainty.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fieldobs uncertainty exlcuding <10% and >90% uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_og = pd.Series(color_data)\n",
    "other_bool = ~cc_og.isin([0,1,100])\n",
    "cc = cc_og[other_bool]\n",
    "cc_vc = cc.value_counts(ascending = False)\n",
    "gt10_bool = (cc_vc.index > 10) & (cc_vc.index < 90)\n",
    "cc_vc[gt10_bool].shape\n",
    "#cc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actual_cc.shape)\n",
    "print(cc_bool.shape)\n",
    "print(sensors_cc.shape)\n",
    "print(cc_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#color_data = fr_uncertainty * 100\n",
    "color_data = np.round(fr_uncertainty,2) * 100\n",
    "cc_og = pd.Series(color_data)\n",
    "cc_bool = (cc_og < 97.5) & (cc_og > 2.5)\n",
    "cc_new = cc_og[cc_bool]\n",
    "sensors_cc = sensors.loc[cc_bool, :]\n",
    "actual_cc = actual[np.where(cc_bool)]\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = plt.gca()\n",
    "\n",
    "formatted_text = ['{:.0f}\\%'.format(t) for t in cc_new]\n",
    "markers = ['o', '*']\n",
    "marker_idx = 0\n",
    "for unq in np.unique(actual_cc):\n",
    "    print(unq)\n",
    "    unq_bool = (actual_cc == unq).flatten()\n",
    "    plt.scatter(\n",
    "        sensors_cc.loc[unq_bool, 'x'].values, sensors_cc.loc[unq_bool,'y'].values,\n",
    "        c = cc_new[unq_bool],\n",
    "        marker=markers[marker_idx],\n",
    "        vmin=0,vmax=100,label=layer_dict[unq],edgecolor='black',linewidth=0.1,\n",
    "    )\n",
    "    marker_idx+=1\n",
    "\n",
    "leg = ax.legend()\n",
    "leg.legendHandles[0].set_color('white')\n",
    "leg.legendHandles[0].set_edgecolor('black')\n",
    "leg.legendHandles[0].set_linewidth(0.5)\n",
    "leg.legendHandles[1].set_color('white')\n",
    "leg.legendHandles[1].set_edgecolor('black')\n",
    "leg.legendHandles[1].set_linewidth(0.5)\n",
    "\n",
    "# add annotations with the following\n",
    "#for x, y, txt in zip(sensors_cc['x'], sensors_cc['y'], formatted_text):ax.annotate(txt, (x+np.random.choice([200,-200,400,-400]), y+np.random.choice([200,-200, 400,-400])),verticalalignment='bottom')\n",
    "\n",
    "_ = plt.xlabel('Eastings (km)',fontsize=fontsize)\n",
    "_ = plt.ylabel('Northings (km)',fontsize=fontsize)\n",
    "\n",
    "cbt = [0, 50, 100]\n",
    "cbtl = ['{:.0f}\\%'.format(cbt_i) for cbt_i in cbt]\n",
    "cb = plt.colorbar(ticks = cbt)\n",
    "cb.set_ticklabels(cbtl)\n",
    "cb.ax.tick_params(labelsize=fontsize)\n",
    "cb.set_label('Durlacher Supersuite \\% Certainty',fontsize=fontsize)\n",
    "\n",
    "ticks = [0, 7500, 15000]\n",
    "tick_labels = [\n",
    "    '{:.0f}'.format(tick/1000) if float(tick/1000).is_integer()\n",
    "    else '{:.1f}'.format(tick/1000)\n",
    "    for tick in ticks\n",
    "]\n",
    "\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_yticklabels(tick_labels,fontsize=fontsize)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels(tick_labels,fontsize=fontsize)\n",
    "\n",
    "ax.set_xlim(0, 15000)\n",
    "ax.set_ylim(0, 15000)\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('/Users/davidkohn/Desktop/fieldobs-uncertainty-subsection.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_from_actual = (actual.flatten() - np.round(fr_uncertainty,2)) * 100\n",
    "#nonzero_diff_bool = (difference_from_actual != 0).flatten()\n",
    "nonzero_diff_bool = (np.abs(difference_from_actual) > 10).flatten()\n",
    "nonzero_diff_idx = np.where(nonzero_diff_bool)\n",
    "sensors_nz = sensors.loc[nonzero_diff_bool, :]\n",
    "difference_from_actual_nz = np.abs(difference_from_actual[nonzero_diff_idx])\n",
    "fr_uncertainty_nz = np.round(fr_uncertainty[nonzero_diff_bool],2)*100\n",
    "actual_nz = actual[nonzero_diff_idx]\n",
    "\n",
    "marker_idx = 0\n",
    "f = plt.figure(figsize=(5,5))\n",
    "ax = plt.gca()\n",
    "for unq in np.unique(actual_nz):\n",
    "    print(unq)\n",
    "    unq_bool = (actual_nz == unq).flatten()\n",
    "    plt.scatter(\n",
    "        sensors_nz.loc[unq_bool, 'x'].values, sensors_nz.loc[unq_bool,'y'].values,\n",
    "        c = fr_uncertainty_nz[unq_bool],\n",
    "        #c = difference_from_actual_nz[unq_bool],\n",
    "        marker=markers[marker_idx],\n",
    "        vmin=0,vmax=100,label=layer_dict[unq],edgecolor='black',linewidth=0.1,\n",
    "    )\n",
    "    marker_idx+=1\n",
    "\n",
    "_ = plt.xlabel('Eastings (km)',fontsize=fontsize)\n",
    "_ = plt.ylabel('Northings (km)',fontsize=fontsize)\n",
    "\n",
    "cbt = [0, 50, 100]\n",
    "cbtl = ['{:.0f}\\%'.format(cbt_i) for cbt_i in cbt]\n",
    "cb = plt.colorbar(ticks = cbt)\n",
    "cb.set_ticklabels(cbtl)\n",
    "cb.ax.tick_params(labelsize=fontsize)\n",
    "#cb.set_label('\\% Difference From Actual',fontsize=fontsize)\n",
    "cb.set_label('Durlacher Supersuite \\% Certainty',fontsize=fontsize)\n",
    "\n",
    "ticks = [0, 7500, 15000]\n",
    "tick_labels = [\n",
    "    '{:.0f}'.format(tick/1000) if float(tick/1000).is_integer()\n",
    "    else '{:.1f}'.format(tick/1000)\n",
    "    for tick in ticks\n",
    "]\n",
    "\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_yticklabels(tick_labels,fontsize=fontsize)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels(tick_labels,fontsize=fontsize)\n",
    "\n",
    "ax.set_xlim(0, 15000)\n",
    "ax.set_ylim(0, 15000)\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('/Users/davidkohn/Desktop/fieldobs-test.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p-hat posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(5,5))\n",
    "ax = plt.gca()\n",
    "n_samples = fr.shape[0]\n",
    "n_points = fr.shape[1]\n",
    "fr_sum = fr.sum(axis = 1)\n",
    "fracs = fr_sum / n_points\n",
    "weights = np.ones((n_samples,1))/n_samples\n",
    "plt.hist(\n",
    "    fracs, bins = 20, weights = weights, fill=None\n",
    ")\n",
    "\n",
    "mean = np.mean(fracs)\n",
    "plt.axvline(mean,c='red')\n",
    "\n",
    "yt = ax.get_yticks()[1:-1]\n",
    "ytl = ['{:.0f}\\%'.format(yt_i * 100) for yt_i in yt]\n",
    "_ = ax.set_yticks(yt)\n",
    "_ = ax.set_yticklabels(ytl)\n",
    "\n",
    "xt = ax.get_xticks()[1:-1]\n",
    "xtl = ['{:.0f}\\%'.format(xt_i * 100) for xt_i in xt]\n",
    "_ = ax.set_xticks(xt)\n",
    "_ = ax.set_xticklabels(xtl)\n",
    "\n",
    "_ = plt.xlabel('$\\hat{p}$')\n",
    "_ = plt.ylabel('Posterior probability')\n",
    "plt.savefig('/Users/davidkohn/Desktop/fieldobs-p.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter mean table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_title_list = ['Layer 0', 'Layer 1']\n",
    "p_list = [p.capitalize() for p in param_title_list]\n",
    "\n",
    "table = pd.DataFrame(0, index = layer_title_list, columns = p_list)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for samples_key, layer_title in zip(param_key_list, layer_title_list):\n",
    "    for param_idx, param_title in zip(param_idx_list, p_list):\n",
    "        param = samples[samples_key][:, param_idx]\n",
    "        stat = param.mean()\n",
    "        #print('{} {} {}'.format(samples_key, param_title, param.mean()))\n",
    "        table.loc[layer_title, param_title] = stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv('/Users/davidkohn/Desktop/mean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voxel plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put together file paths\n",
    "dir_output_voxels = 'output/plots-voxels'\n",
    "search_str = 'voxel'\n",
    "dir_voxels = 'voxels'\n",
    "#dir_voxels = ''\n",
    "if author == 'dk':\n",
    "    fpath_in_list = [\n",
    "        get_fname_list(os.path.join(dir_parent, exp_str, num, dir_voxels), search_str)\n",
    "        for num in num_list\n",
    "    ]\n",
    "    dir_out_list = [\n",
    "        os.path.join(dir_parent, exp_str, num, dir_output_voxels)\n",
    "        for num in num_list\n",
    "    ]\n",
    "elif author == 'rs':\n",
    "    fpath_in_list = [\n",
    "        get_fname_list(os.path.join(dir_parent, exp_str + num), search_str)\n",
    "        for num in num_list\n",
    "    ]\n",
    "    dir_out_list = [\n",
    "        os.path.join(dir_parent, exp_str + num, dir_output_voxels)\n",
    "        for num in num_list\n",
    "    ]\n",
    "print(fpath_in_list)\n",
    "print(dir_out_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_save_template_str = 'posterior-layer-{:02}.{}'\n",
    "view_list = []\n",
    "for voxel_path_list, dir_out in zip(fpath_in_list, dir_out_list):\n",
    "    if voxel_path_list:\n",
    "        view = plot_layer_posteriors(voxel_path_list, dir_out)\n",
    "        view_list.append(view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = fpath_in_list[0][0]\n",
    "v = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v['boundary0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_layer0 = view.fbounds[0]\n",
    "fb_layer1 = view.fbounds[1]\n",
    "#fb = fb.mean(axis = 0)\n",
    "#cond = fb == 0\n",
    "#print(cond.sum())\n",
    "#print(71 * 36 * 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = -1\n",
    "fb_layer0_sample = fb_layer0[sample_idx,:,:]\n",
    "fb_layer1_sample = fb_layer1[sample_idx,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_layer0_sample.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_cond = fb_layer0_sample == 0 \n",
    "zero_cond.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_cond = fb_layer1_sample == 0 \n",
    "zero_cond.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.where(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb[x[0], y[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_idx = 0\n",
    "layer_idx = 1\n",
    "sample_idx = -1\n",
    "\n",
    "view = view_list[view_idx]\n",
    "layer_voxels = view.layers[layer_idx][0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.layers[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(view.layers[0][-1, :, 0, 0].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(view.layers[1][-1, :, 0, 0].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(view.fbounds[0][-1,0,0])\n",
    "print(view.fbounds[1][-1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_voxels[x[0], y[0], 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.rockprops['Density'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "view.layers[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_voxels[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_idx = 0\n",
    "layer_idx = 0\n",
    "sample_idx = -1\n",
    "\n",
    "view = view_list[view_idx]\n",
    "layer_voxels = view.layers[layer_idx]\n",
    "sample_voxels = layer_voxels[sample_idx,:,:,:]\n",
    "\n",
    "fb = view.fbounds[layer_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_layer_bounds = fb.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_layer_bounds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(view.layers[0][-1,:,:,:] + view.layers[1][-1,:,:,:]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(view.layers[0][-1,:,:,0] != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "344/(36*82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = view.layers[0][-1,:,:,:]\n",
    "l[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = view.layers[1][-1,:,:,:]\n",
    "l[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.fbounds[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size = view.zbounds[1]/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.fbounds[1][-1].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(view.fbounds[0][-1, :, :] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(view.fbounds[1][-1, :, :] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(view.fbounds[0][-1].flatten() == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(view.fbounds[1][-1].flatten() == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.fbounds[1][-1].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(view.fbounds[1][-1].flatten() < voxel_size).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view = a specific experiment in the list\n",
    "view_idx = 0\n",
    "layer_idx = 1\n",
    "\n",
    "view = view_list[view_idx]\n",
    "layer_voxels = view.meanlayer(layer_idx)\n",
    "#view_idx = 0\n",
    "#layer_idx = 1\n",
    "#sample_idx = -1\n",
    "\n",
    "#view = view_list[view_idx]\n",
    "#layer_voxels = view.layers[layer_idx][sample_idx,:,:,:]\n",
    "#l = view.layers[0][-1,:,:,:]\n",
    "\n",
    "app = vv.use()\n",
    "vv.figure(1)\n",
    "vv.settings.figureSize = (100, 100)\n",
    "vv.xlabel('East (voxels)')\n",
    "vv.ylabel('North (voxels)')\n",
    "vv.zlabel('Depth (voxels)')\n",
    "a = vv.gca()\n",
    "print(a.GetView())\n",
    "#a.loc = (0, 0, 100)\n",
    "#a.azimuth = 100\n",
    "#a.camera.fov = 10\n",
    "a.daspect = 1, 1, -1\n",
    "a.camera.elevation = -90\n",
    "#a.camera.azimuth = 30\n",
    "a.camera.roll = 10\n",
    "print(a.GetView())\n",
    "print(a.camera)\n",
    "#a.camera.\n",
    "a.SetView()\n",
    "#t = vv.volshow(l, cm=vv.CM_JET)\n",
    "#t = vv.volshow(layer_voxels, cm=vv.CM_JET, renderStyle='ray')\n",
    "t = vv.volshow(layer_voxels, cm=vv.CM_JET)\n",
    "vv.ColormapEditor(a)\n",
    "app.Run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually run visvis so you can move the plot around\n",
    "fpath_idx = 6\n",
    "layer_idx = 0\n",
    "fn = fpath_in_list[fpath_idx][0]\n",
    "print('filename: {}'.format(fn)\n",
    "n_layers = len(view.layers)\n",
    "print('no layers: {}'.format(n_layers)\n",
    "view = geovis_notebook_version.MasonView(fn)\n",
    "layer_voxels = view.meanlayer(layer_idx)\n",
    "\n",
    "app = vv.use()\n",
    "vv.figure(1)\n",
    "vv.xlabel('Eastings (units)')\n",
    "vv.ylabel('Northings (units)')\n",
    "vv.zlabel('Depth (units)')\n",
    "a = vv.gca()\n",
    "print(a.GetView())\n",
    "#a.loc = (0, 0, 100)\n",
    "#a.azimuth = 100\n",
    "#a.camera.fov = 10\n",
    "a.daspect = 1, 1, -1\n",
    "a.camera.elevation = -90\n",
    "#a.camera.azimuth = 30\n",
    "a.camera.roll = 10\n",
    "print(a.GetView())\n",
    "print(a.camera)\n",
    "#a.camera.\n",
    "a.SetView()\n",
    "t = vv.volshow(layer_voxels, cm=vv.CM_JET)\n",
    "#t = vv.volshow(layer_voxels, cm=vv.CM_JET, renderStyle='ray')\n",
    "vv.ColormapEditor(a)\n",
    "app.Run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = '/Users/davidkohn/Desktop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = plt.gca()\n",
    "try:\n",
    "    plt.rc('text', usetex = True)\n",
    "    plt.rc('font', family = 'serif')\n",
    "except:\n",
    "    pass\n",
    "plt.contourf(layer_voxels[0])\n",
    "plt.colorbar()\n",
    "\n",
    "plt.xlabel('Eastings (km)')\n",
    "plt.ylabel('Northings (km)')\n",
    "\n",
    "fname = 'surface.eps'\n",
    "fpath = os.path.join(parent_dir, fname)\n",
    "plt.savefig(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_voxels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ipy361]",
   "language": "python",
   "name": "conda-env-ipy361-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
